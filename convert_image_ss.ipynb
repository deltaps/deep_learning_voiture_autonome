{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sacha\\anaconda3\\envs\\deepLearningVehicule\\lib\\site-packages\\torchvision\\models\\_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import flash\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.image import SemanticSegmentation, SemanticSegmentationData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL\n",
    "import os\n",
    "import torch.utils.data.dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {(0, 0, 0, 255): (0, 0, 0, 255),\n",
    "              (70, 70, 70, 255): (1, 0, 0, 255),\n",
    "              (100, 40, 40, 255): (2, 0, 0, 255),\n",
    "              (55, 90, 80, 255): (3, 0, 0, 255),\n",
    "              (220, 20, 60, 255): (4, 0, 0, 255),\n",
    "              (153, 153, 153, 255): (5, 0, 0, 255),\n",
    "              (157, 234, 50, 255): (6, 0, 0, 255),\n",
    "              (128, 64, 128, 255): (7, 0, 0, 255),\n",
    "              (244, 35, 232, 255): (8, 0, 0, 255),\n",
    "              (107, 142, 35, 255): (9, 0, 0, 255),\n",
    "              (0, 0, 142, 255): (10, 0, 0, 255),\n",
    "              (102, 102, 156, 255): (11, 0, 0, 255),\n",
    "              (220, 220, 0, 255): (12, 0, 0, 255),\n",
    "              (70, 130, 180, 255): (13, 0, 0, 255),\n",
    "              (81, 0, 81, 255): (14, 0, 0, 255),\n",
    "              (150, 100, 100, 255): (15, 0, 0, 255),\n",
    "              (230, 150, 140, 255): (16, 0, 0, 255),\n",
    "              (180, 165, 180, 255): (17, 0, 0, 255),\n",
    "              (250, 170, 30, 255): (18, 0, 0, 255),\n",
    "              (110, 190, 160, 255): (19, 0, 0, 255),\n",
    "              (170, 120, 50, 255): (20, 0, 0, 255),\n",
    "              (45, 60, 150, 255): (21, 0, 0, 255),\n",
    "              (145, 170, 100, 255): (22, 0, 0, 255)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10001,10002):\n",
    "    im = PIL.Image.open('data3/Town01/generated/images_ss/' + str(i) + '.png')\n",
    "    width, height = im.size\n",
    "    #Cr√©er une nouvelle image\n",
    "    new_pixels = [(0, 0, 0,255)] * (width * height)\n",
    "    for idx, pixel in enumerate(im.getdata()):\n",
    "        if pixel in color_dict:\n",
    "            new_pixels[idx] = color_dict[pixel]\n",
    "    newim = PIL.Image.new(im.mode, im.size)\n",
    "    newim.putdata(new_pixels)\n",
    "\n",
    "    #Sauvegarder l'image\n",
    "    newim.save('data3/Town01/generated/image_ss_new/' + str(i) + '.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearningVehicule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
