{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PROJET ANNUEL Véhicule autonome et Deep Learning\n",
    "## PRONOST Sacha, NEVEU Thomas, VASSE Thomas, BERNEAUD Noah"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import flash\n",
    "from flash.core.data.utils import download_data\n",
    "from flash.image import SemanticSegmentation, SemanticSegmentationData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import PIL\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data.dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchmetrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-06T23:05:02.757016Z",
     "start_time": "2023-05-06T23:04:32.582657Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Les données récupérées sont sur le [lien](https://npm3d.fr/kitti-carla) suivant:\n",
    " https://npm3d.fr/kitti-carla\n",
    " #### (Il faut les traiter à l'aide du fichier 'convert_image_ss' au préalable)\n",
    "### Les anciennes données sont sur le [lien](https://github.com/ongchinkiat/LyftPerceptionChallenge/releases/download/v0.1/carla-capture-20180513A.zip) suivant:\n",
    " https://github.com/ongchinkiat/LyftPerceptionChallenge/releases/download/v0.1/carla-capture-20180513A.zip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T23:05:09.211326Z",
     "start_time": "2023-05-06T23:05:09.138301Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Séparation de la donnée\n",
    "X = []\n",
    "for filename in os.listdir('data/Town01/generated/images_rgb/'):\n",
    "    X.append('data/Town01/generated/images_rgb/'+filename)\n",
    "y = []\n",
    "for filename in os.listdir('data/Town01/generated/image_ss_new/'):\n",
    "    y.append('data/Town01/generated/image_ss_new/'+filename)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556a99b-1d2c-416c-b376-1a8d23aba5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T23:05:10.943677Z",
     "start_time": "2023-05-06T23:05:10.841294Z"
    }
   },
   "outputs": [],
   "source": [
    "datamodule = SemanticSegmentationData.from_files(\n",
    "    train_files=X_train,\n",
    "    train_targets=y_train,\n",
    "    val_split=0.1,\n",
    "    transform_kwargs=dict(image_size=(256, 256)),\n",
    "    num_classes=23,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28d5f668-eee1-48ee-9bd0-cae25b82dc3d",
   "metadata": {},
   "source": [
    "# Vérification des images d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c74b6-87ad-4805-9814-c86cecefae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(datamodule.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2559a7-f7d1-4a9f-9d8d-e6b5e2d9f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5217d12-2fcc-45d9-87e6-48fbef9b0b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = data['input'][0]\n",
    "y = data['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5eba6-188d-4ce7-aa43-fa4ad5ee61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im.numpy().transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcbeda-537c-4b37-9615-092722ef5998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34d067cc-ca61-4a1f-b0fe-9ad62c72149e",
   "metadata": {},
   "source": [
    "# Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a21957-ee88-43a9-8c90-f6689fe4ca33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T23:05:16.071371Z",
     "start_time": "2023-05-06T23:05:14.078445Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SemanticSegmentation(\n",
    "    #backbone=\"mobilenetv3_large_100\",\n",
    "    backbone=\"resnet50\",\n",
    "    head=\"fpn\",\n",
    "    num_classes=datamodule.num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9bd250-f479-4fb4-9bb0-aec18071a098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T20:29:59.030598Z",
     "start_time": "2023-05-06T16:50:08.459415Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = flash.Trainer(max_epochs=3, accelerator='tpu')#torch.cuda.device_count())\n",
    "trainer.finetune(model, datamodule=datamodule, strategy=\"freeze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du modèle\n",
    "trainer.save_checkpoint(\"model/modelMobileNetWithTestSplit.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T23:05:22.451380Z",
     "start_time": "2023-05-06T23:05:19.418605Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 'mobilenetv3_large_100' provided by qubvel/segmentation_models.pytorch (https://github.com/qubvel/segmentation_models.pytorch).\n",
      "Using 'fpn' provided by qubvel/segmentation_models.pytorch (https://github.com/qubvel/segmentation_models.pytorch).\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "#Si le modèle est déjà crée, l'ouvrir et le charger\n",
    "model = model.load_from_checkpoint('model/modelMobileNetWithTestSplit.pt')\n",
    "trainer = flash.Trainer(max_epochs=3, gpus=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Teste de quelques images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8678f6-384b-483f-b8f7-015d239bc64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = SemanticSegmentationData.from_files(\n",
    "    predict_files=[\n",
    "        \"data/Town01/generated/images_rgb/2.png\"\n",
    "    ],\n",
    "    batch_size=3,\n",
    ")\n",
    "predictions = trainer.predict(model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946bfd23-b059-4cf6-8c5a-32d2b3f5e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_im_test = predictions[0][0]['input']\n",
    "out_im_test = predictions[0][0]['preds']\n",
    "\n",
    "in_im_test=in_im_test.numpy().transpose(1,2,0)\n",
    "in_im_test=(in_im_test-np.min(in_im_test))/(np.max(in_im_test)-np.min(in_im_test))\n",
    "\n",
    "out_im_test = torch.argmax(out_im_test,0)\n",
    "\n",
    "#plt.imshow(in_im_test[:,:,0],cmap='gray')\n",
    "plt.imshow(in_im_test)\n",
    "plt.imshow(out_im_test,alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a39daa95-b896-4d72-a492-73661dedcce4",
   "metadata": {},
   "source": [
    "# Verification des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d9043-067e-475a-b1d0-7bcbac0f7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = SemanticSegmentationData.from_files(\n",
    "    test_files=[\n",
    "        \"data/Town01/generated/images_rgb/2.png\",\n",
    "        \"data/Town01/generated/images_rgb/4.png\",\n",
    "        \"data/Town01/generated/images_rgb/6.png\",\n",
    "    ],\n",
    "    test_targets=[\n",
    "        \"data/Town01/generated/image_ss_new/2.png\",\n",
    "        \"data/Town01/generated/image_ss_new/4.png\",\n",
    "        \"data/Town01/generated/image_ss_new/6.png\",\n",
    "    ],\n",
    "    transform_kwargs=dict(image_size=(256, 256)),\n",
    "    num_classes=23,    \n",
    "    batch_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495e01f-a0a1-49d9-8fab-7b858dbe1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(datamodule.test_dataloader()))\n",
    "im = data['input'][0]\n",
    "y = data['target'][0]\n",
    "\n",
    "plt.imshow(im.numpy().transpose(1,2,0))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(y)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7db8c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Préparation de la donnée\n",
    "X_test = X_test[:100]\n",
    "y_test = y_test[:100]\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22428c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacha\\anaconda3\\envs\\deepLearningVehicule\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:69: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d692eb44246d477496a41a7bdc0d3eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modulePred = SemanticSegmentationData.from_files(\n",
    "        predict_files=X_test,\n",
    "        batch_size=1,\n",
    ")\n",
    "predictions = trainer.predict(model, datamodule=modulePred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T22:39:52.264962Z",
     "start_time": "2023-05-06T22:39:50.438740Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy actuelle:  tensor(0.9234)\n",
      "Accuracy moyenne:  tensor(0.9234)\n",
      "Accuracy actuelle:  tensor(0.9080)\n",
      "Accuracy moyenne:  tensor(0.9140)\n",
      "Accuracy actuelle:  tensor(0.9097)\n",
      "Accuracy moyenne:  tensor(0.9125)\n",
      "Accuracy actuelle:  tensor(0.9055)\n",
      "Accuracy moyenne:  tensor(0.9147)\n",
      "Accuracy actuelle:  tensor(0.9032)\n",
      "Accuracy moyenne:  tensor(0.9099)\n",
      "Accuracy actuelle:  tensor(0.8659)\n",
      "Accuracy moyenne:  tensor(0.9082)\n",
      "Accuracy actuelle:  tensor(0.9141)\n",
      "Accuracy moyenne:  tensor(0.9083)\n",
      "Accuracy actuelle:  tensor(0.9466)\n",
      "Accuracy moyenne:  tensor(0.9094)\n",
      "Accuracy actuelle:  tensor(0.9140)\n",
      "Accuracy moyenne:  tensor(0.9093)\n",
      "Accuracy actuelle:  tensor(0.9300)\n",
      "Accuracy moyenne:  tensor(0.9101)\n",
      "tensor(0.9099)\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "accuracyMetric = torchmetrics.Accuracy(multiclass=True,num_classes=23)\n",
    "moduleTest = SemanticSegmentationData.from_files(\n",
    "        test_files=X_test,\n",
    "        test_targets=y_test,\n",
    "        batch_size=1,\n",
    "    )\n",
    "toPrint = [0,10,20,30,40,50,60,70,80,90]\n",
    "for i in range(100):\n",
    "    prediction = torch.argmax(predictions[i][0]['preds'], 0).flatten()\n",
    "    true = moduleTest.test_dataloader().dataset[i]['target'].flatten()\n",
    "\n",
    "    #Conversion de ce qui ce trouve dans le tensor predictions et true en int\n",
    "    prediction = prediction.numpy().astype(int)\n",
    "    true = true.numpy().astype(int)\n",
    "    #Converstion de predictions et true en tensor\n",
    "    prediction = torch.from_numpy(prediction)\n",
    "    true = torch.from_numpy(true)\n",
    "    #print(true.flatten().shape)\n",
    "    accuracy += accuracyMetric(prediction, true)\n",
    "    if(i in toPrint):\n",
    "        print(\"Accuracy actuelle: \",accuracyMetric(prediction, true))\n",
    "        print(\"Accuracy moyenne: \",accuracy/(i+1))\n",
    "print(accuracy/len(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
